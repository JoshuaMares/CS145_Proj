{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## katchi code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12489 entries, 0 to 12488\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   info_sentence  12489 non-null  object\n",
      " 1   meta           12489 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 195.3+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DebertaTokenizer, DebertaForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv('final.csv')  # replace with your csv file\n",
    "df.info()\n",
    "\n",
    "# Use the sample data on my local machine. Please change it when running on VM\n",
    "texts = random.sample(df['info_sentence'].tolist(), 100)\n",
    "labels = random.sample(df['meta'].tolist(), 100)\n",
    "\n",
    "\n",
    "# Split into training and validation before converting to tensors\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2)\n",
    "\n",
    "# load tokenizer and model\n",
    "tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base')\n",
    "\n",
    "# tokenize data for training set\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "train_encodings['labels'] = torch.tensor(train_labels)\n",
    "\n",
    "# tokenize data for validation set\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "val_encodings['labels'] = torch.tensor(val_labels)\n",
    "\n",
    "# Convert encodings to a Dataset format\n",
    "class CardInfoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a9d908d76846d4abf89e3f8d2d20cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wj/2bdfjxmx6_dd5gvnsyg6_rvc0000gn/T/ipykernel_10645/2178468020.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 98.0359, 'train_samples_per_second': 2.448, 'train_steps_per_second': 0.153, 'train_loss': 0.648587417602539, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_dataset = CardInfoDataset(train_encodings)\n",
    "val_dataset = CardInfoDataset(val_encodings)\n",
    "\n",
    "#function to compute accuracy\n",
    "def compute_accuracy(preds, labels):\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    return accuracy_score(labels, preds)\n",
    "\n",
    "\n",
    "# define the training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          \n",
    "    num_train_epochs=3,              \n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=64,   \n",
    "    warmup_steps=500,                \n",
    "    weight_decay=0.01,               \n",
    "    logging_dir='./logs',            \n",
    ")\n",
    "\n",
    "model = DebertaForSequenceClassification.from_pretrained('microsoft/deberta-base', num_labels=len(set(labels)))\n",
    "\n",
    "# create the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         \n",
    "    args=training_args,                  \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=lambda pred: {\"accuracy\": compute_accuracy(pred.predictions, pred.label_ids)}             \n",
    ")\n",
    "\n",
    "# train the model\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "# save the model\n",
    "model.save_pretrained(\"./deberta_model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f5c067dbf54190acb3f4f795d2d6c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Magician Girl\tPredicted Label: 0\n",
      "Input: Blue-Eyes White Dragon\tPredicted Label: 0\n",
      "Input: Saint Dragon - The God of Osiris\tPredicted Label: 0\n"
     ]
    }
   ],
   "source": [
    "# ... existing code ...\n",
    "\n",
    "# Input data for inference\n",
    "input_data = [\"Magician Girl\", \"Blue-Eyes White Dragon\", \"Saint Dragon - The God of Osiris\"]\n",
    "\n",
    "# Preprocess the input data\n",
    "input_encodings = tokenizer(input_data, truncation=True, padding=True)\n",
    "\n",
    "# Create a dataset for inference\n",
    "inference_dataset = CardInfoDataset(input_encodings)\n",
    "\n",
    "# Perform inference using the trained model\n",
    "predictions = trainer.predict(test_dataset=inference_dataset)\n",
    "\n",
    "# Get the predicted labels\n",
    "predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# Print the predicted labels\n",
    "for input_text, label in zip(input_data, predicted_labels):\n",
    "    print(f\"Input: {input_text}\\tPredicted Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
